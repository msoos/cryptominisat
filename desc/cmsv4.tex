%\documentclass[runningheads]{llncs}
\documentclass[final]{ieee}

\usepackage{microtype} %This gives MUCH better PDF results!
%\usepackage[active]{srcltx} %DVI search
\usepackage[cmex10]{amsmath}
\usepackage{amssymb}
\usepackage{fnbreak} %warn for split footnotes
\usepackage{url}
%\usepackage{qtree} %for drawing trees
%\usepackage{fancybox} % if we need rounded corners
%\usepackage{pict2e} % large circles can be drawn
%\usepackage{courier} %for using courier in texttt{}
%\usepackage{nth} %allows to \nth{4} to make 1st 2nd, etc.
%\usepackage{subfigure} %allows to have side-by-side figures
%\usepackage{booktabs} %nice tables
%\usepackage{multirow} %allow multiple cells with rows in tabular
\usepackage[utf8]{inputenc} % allows to write Faugere correctly
\usepackage[bookmarks=true, citecolor=black, linkcolor=black, colorlinks=true]{hyperref}
\hypersetup{
pdfauthor = {Mate Soos},
pdftitle = {forl},
pdfsubject = {SAT Competition 2013},
pdfkeywords = {SAT Solver, DPLL},
pdfcreator = {PdfLaTeX with hyperref package},
pdfproducer = {PdfLaTex}}
%\usepackage{butterma}

%\usepackage{pstricks}
\usepackage{graphicx,epsfig,xcolor}
\usepackage[algoruled, linesnumbered, lined]{algorithm2e} %algorithms

\begin{document}
\title{forl}
\author{Mate Soos\\Security Research Labs}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\section{Introduction}
This paper presents the defining features of the conflict-driven clause-learning SAT solver \emph{forl}. \emph{forl} aims to be a modern SAT Solver that unifies the ideas present in SatELite~\cite{DBLP:conf/sat/EenB05}, PrecoSat~\cite{precosat}, glucose~\cite{glucose} and  MiniSat~\cite{EenS03MiniSat} with some ideas of the author.

\section{Primary features}

\subsection{Binary implication graphs}
An implication cache mechanism is employed that stores the binary implication graph similarly to stamps~\cite{DBLP:conf/sat/HeuleJB11}. Stamps are also used, as they have been found to aid along with the cache.

\subsection{Clause cleaning}
Clauses are cleaned regularly, but neither activities nor glues are used in the cleaning. Instead, the number of times a clause helped to propagate or caused a conflict is used as a measure of the effectiveness. This measure is reset after every cleaning, so clauses have to regularly prove themselves effective to stay in the database.

\subsection{Implicit Clauses}
Binary and tertiary clauses are stored and handled implicitly. This greatly eases their subsumption and strengthening. Further, it reduces the cost of creating occurrence lists out of these clauses. Implicit clauses are never cleaned.

\subsection{Statistics}
\emph{forl} gathers large amounts of running statistics. Unfortunately they are not yet used to direct search. However, they can be gathered into MySQL and displayed in a web browser. Importing statistics into the database incurs setup costs and about 10\% running cost and so is disabled by default.

\subsection{Time limiting}
For average problems inprocessing techniques tend to work well. However, in case of strange problems (such as problems with billions of binary clauses) they sometimes misbehave. This has been solved with more precise time measurements (measuring effort, not actual time) and sometimes complicated time-out checks.

\subsection{Memory usage}
Memory usage has been greatly improved with precise tracking of where memory is being used. Although memory leaks are not generally an issue given the programming techniques used, temporary allocation of large data structures was a problem. These issues have been fixed through algorithmic means: e.g. through the use of circular swapping for variable renumbering.

\subsection{Hyper-binary resolution and transitive reduction}
On-the-fly hyper-binary resolution~\cite{DBLP:conf/sat/BacchusW03} and transitive reduction has been implemented in both DFS and BFS probing for both irreducible and reducible binaries. This helps on instances with generally acceptable number of binary clauses. For problems with too many binary clauses, transitive reduction can take too much time. Such cases are detected and transitive reduction is turned off.

\subsection{Certified UNSAT}
The DRUP system for certified UNSAT was implemented into \emph{forl}. The current implementation turns on all optimisations  except for XOR-manipulation during certificate generation. However, for stamping and implied literal caching to work, binary clauses must never be DRUP-deleted during variable elimination. This trade-off is questionable, as it might considerably slow down proof checking. As such, there are two versions submitted, one with these options turned on, and one with these options turned off.

\subsection{Disjoint component finding}
Disjoint components are searched for on a regular basis during solving. These disjoint components are solved with a separate solver instance, renumbering the component's variables such as to minimise the startup time of the sub-solver. On certain problems, \emph{forl} can find\&solve thousands of disjoint components within a matter of seconds.

\section{Miscellaneous optimisations}
Hand-rolled memory manager for large clauses, clause offsets instead of pointers, blocking literals, occurrence lists in watchlists, clause abstraction stored in occurrence lists, glue-based and geometric restart selection based on literal polarities, xor detection and manipulation, gate detection and manipulation, variable elimination~\cite{DBLP:conf/sat/EenB05}, subsumption, strengthening, on-the-fly subsumption~\cite{DBLP:conf/sat/HanS09}, recursive conflict clause minimisation~\cite{DBLP:conf/sat/SorenssonB09} (and automatic disabling in case of bad performance), minimisation with stamps\&cache\&binary clauses (and automatic disabling in case of bad performance), blocking of long clauses~\cite{DBLP:conf/tacas/JarvisaloBH10}, equivalent literal replacement, variable renumbering, literal dominator branching thanks to stamps/cache, dominator probing, polarity caching~\cite{DBLP:conf/sat/PipatsrisawatD07}, vivification~\cite{DBLP:conf/ecai/PietteHS08} of long and implicit clauses, watchlist sorting for quasi-
prioritised implicit clause propagation, regular cleaning of false literals of all clauses, detection of long trail and consequent restart blocking in case of satisfiable problems, MiniSat-type variable activities, glue-based extra variable activity bumping, prefetching of watchlists on literal enqueue, optional UIP conflict~\cite{244560} graph generation, probing (with automatic tuning based on past performance), clause subsumption through irreducible stamps and cache, clause strengthening through reducible\&irreducible stamps and cache, precise elimination cost prediction for better elimination order, gradual variable elimination, variable elimination with searching for subsumed\&subsuming product clauses.

\section*{Acknowledgements}
The author would like to thank in no particular order Martin Maurer, Vegard Nossum, Valentin Mayer-Eichberger, George Katsirelos, Karsten Nohl, Luca Melette, Marijn Heule, Vijay Ganesh, Trevor Hansen and Robert Aston for their help.

\bibliographystyle{splncs}
\bibliography{sigproc}

\vfill
\pagebreak

\end{document}
